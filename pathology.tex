% Template for ICASSP-2013 paper; to be used with:
%          spconf.sty  - ICASSP/ICIP LaTeX style file, and
%          IEEEbib.bst - IEEE bibliography style file.
% --------------------------------------------------------------------------
\documentclass{article}
\usepackage{spconf,amsmath,graphicx,bm}
\usepackage{todonotes}
\setlength{\marginparwidth}{1.5cm}

% Example definitions.
% --------------------
\def\x{{\mathbf x}}
\def\L{{\cal L}}

% Title.
% ------
\title{Pathological Speech Processing:\\State-of-the-Art, Current Challenges, and Future Directions}
%
% Single address.
% ---------------
\name{SAILORS, Shrikanth Narayanan}
\address{Signal Analysis and Interpretation Lab,
        University of Southern California,  
  Los Angeles, CA, USA}  
\begin{document}
\ninept
%
\maketitle
%
\begin{abstract}
Speech pathology is a study involving evaluation and treatment of speech production related disorders affecting phonation, fluency, intonation and aeromechanical components of respiration.
Recently, speech pathology has garnered special interest amongst machine leaning and signal processing scientists.
This growth in interest is lead by advances in disciplines such as data collection technology, data science, computational models and speech processing. 
With the evolution of scientific instruments in these fields, scientists have endeavored to understand both the cause and effects of speech pathology conditions.  
In this paper, we review the application of machine learning and signal processing techniques to speech pathology.
We focus on three aspects: challenges in the application of ML-SP tools within the domain; a review of proposed knowledge-based and data-driven approaches; and case studies directed towards pathological speech analysis.
By listing the challenges, novel aspects addressed and suggested future work, we aim to review and inform the course of this cross-disciplinary study.
    
 
\end{abstract}
%
\begin{keywords}
Pathological speech, machine learning, speech processing 
\end{keywords}
%
\section{Introduction}
\label{sec:intro}
The American Speech-Language Hearing Association (ASHA) \cite{american2008council} categorizes pathological disorders into five categories, namely (i) speech disorders, (ii) language disorders, (iii) social communication disorders, (iv) cognitive communication disorders, and (v) swallowing disorders. With the evolution of scientific instruments, pathologists have made large strides in the understanding of pathological disorders in all five of these categories. Speech disorders are also of considerable interest to speech scientists, both for applying existing knowledge of human speech production and perception and for performing novel experiments. A specific cross-disciplinary approach that is increasingly popular utilizes machine learning and signal processing (ML-SP) tools to investigate patterns in pathological voices. In this work, we present a critical review of ML-SP applications in speech pathology, considering the promises and pitfalls within this growing domain. 
We list recent advances made in speech pathology aided by ML-SP tools as well as problems that can be addressed in the near future. 
Specifically, we focus on three aspects: (i) challenges in the application of ML-SP tools within the domain; (ii) a review of proposed knowledge-based and data-driven approaches; and (iii) an investigation a few case studies directed towards pathological speech analysis.
By addressing each of these topics, we aim to assess the current state of the art and inform future endeavors in the application of ML-SP tools to pathological speech. 

\subsection{Background}
Within the characterization of speech pathological disorders, Van der Merwe \cite{van1997characterization,mcneil2009clinical} provides a sound theoretical foundation. 
Citing several speech language pathologists \cite{mcneil1990motoric,kent1987relative,marquardt1984elusive}, she emphasizes on the need for a speech production framework for research and management of pathological disorders. 
To address this, she describes a four level framework characterizing pathological speech as a dysfunction at the levels of linguistic-symbolic planning and speech motor planning. 
Further in \cite{mcneil2009clinical}, Kent, Ballard et al. and Forrest et al. describe assessment/ examination methods for motor speech disorders and speech production mechanism. 
Later, Kent \cite{kent2000research} reviewed research on speech motor control and its disorders.
Particular emphasis has also been laid on specific speech language and disorders such as apraxia \cite{wambaugh2002summary}, dysarthria \cite{yorkston2007evidence}, sluttering \cite{bothe2006stuttering}, and voice disorders (e.g., hoarseness, spasmodic dysphonia) \cite{aronson2011clinical}. 
Apart from this, pathology researchers have also investigated speech disorders in specific population groups such as children with developmental disorders \cite{millar2006impact,schlosser2008effects}, people with schizophrenia \cite{delisi2001speech} and Parkinson's disease \cite{critchley1981speech}.

Application of ML-SP techniques to the domain of speech pathology is not new and \cite{rees1973auditory,davis1979acoustic,robin1989auditory} are some of the earlier works that made use of contemporary ML-SP tools towards the understanding of pathological disorders. 
The progress of this study over years can be tracked using works such as \cite{hillenbrand1994acoustic,abberton1989laryngographic,manfredi2000adaptive}.
Over the last decade, advances in the field of machine learning has lead to several investigations laying special focus on detection of these speech disorders \cite{fonseca2007wavelet,chee2009mfcc}. Following this, various Interspeech challenges \cite{schuller2012interspeech,}, further attracted special interest in the application of ML-SP techniques to detection and analysis of pathological conditions.  
In this work, we summarize these and various other inter-disciplinary approaches investigating pathological speech disorders using speech processing, acoustic signal processing and machine learning tools.
%Although, a considerable amount of research has presented novel Signal Processing (SP)/Machine Learning (ML) schemes with relation to pathological speech, we investigate three factors: (i) challenges in application of (ML-SP) to the domain of pathological speech understanding (ii) domain knowledge driven analysis (ex: feature design, machine learning algorithms) of pathological speech characteristics and, (iii) design of specific case studies to investigate pathological speech.
Over the course of this paper, we discuss the challenges, both knowledge and data driven approaches and case study designs. 
%Over the course of this paper, 
We draw specific examples in each of these topics and point out novel techniques as well as suggest future work.
In the next section, we initiate by stating the challenges in application of ML-SP methods to the study of pathological conditions.
Sections 3 and 4 list a review of the state of the art methods and a few case studies in application of ML-SP tools to study of pathological conditions.
Finally, we present our conclusions in Section 5. 

\section{Challenges and Opportunities in Pathological Speech Conditions}
Advances in understanding the causes and characteristics of pathological conditions have allowed for a theoretically-grounded application of ML-SP techniques to the domain.
However, the sensitive nature of medical research calls for thoroughly listing the objectives and limitations for the experiments being conducted.
In this section, we discuss a few challenges that ML-SP researchers face in dealing with pathology data, and related application opportunities. We note that this list is by no means exhaustive, but certainly needs attention. For example, apart from the outlined challenges, ML-SP researchers also face questions regarding the choice of modeling techniques, variable recording conditions, and finding a balance between data-driven and knowledge-driven modeling (see Section~\ref{sec:domainknowledgeDatadriven}).

\subsection{Defining Pathological Speech}
Several ML-SP algorithms require a specific definition of what is being modeled and investigated.
However due to the evolving nature of the study of pathological speech, definitions are being formulated or revised. 
The Speech Pathology Association of Australia \cite{australia2009criteria} cites several pathologists who describe the terminology in the field as being inconsistent, variable and inadequate. 
This poses a major challenge in terms of ML-SP research as it could turn out to be inaccurate or irrelevant as the definitions change.
Apart from this, ML-SP algorithms also need to be cautiously designed keeping in mind the spectrum of pathological speech conditions.
For instance, just within aphasia, the severity could be categorized into anomic, Wernicke's, mixed non-fluent, Broca's, or global aphasia \cite{mesulam1992primary}. 
As there may or may not be a transfer of knowledge in understanding these conditions, the specificity and generality of symptoms being addressed should be laid out clearly for a larger impact and clearer understanding of pathological conditions. 


\subsection{Subjective Impressions}
Another challenge is due to the subjectivity of human perception of pathological speech. In the vast majority of cases, ML-SP algorithms are trained to model speech patterns using judgements from expert pathologists.
Although pathologists serve as the ground-truth, a single rater will be affected by their own personal experiences and training, as well as secondary features like their mood and attention. The issue of intra-rater variability is exacerbated by the previous argument relating to the evolving nature of definitions of pathological speech, wherein variability is increased due to the revised definitions. Therefore, an effective system will have to understand intra-rater variability. For example, recent research has sought to find the most reliable regions for individual raters~\cite{audhkhasi2013globally}. This challenge also presents an opportunity. Ideally, the automatic system may predict a collective judgement made by many experts, which in effect could augment the perceptions of a single clinician.

\subsection{Patient Variability}
\label{sec:PatVar}
Another factor impacting the quality of ML-SP algorithms is the variability among patients within a specific pathological condition population. 
As often the goal of these algorithms is to capture speech/vocal patterns for each pathological condition, patient specific variability serves as a source of noise. Moreover, this variability can occur both across speakers and within speakers. In terms of experimental setup, a common approach for dealing with inter-speaker variability is to control the speech content, particularly through reading tasks--the major drawback being that reading tasks lack spontaneous speech planning which may be relevant for certain disorders.
There are also computational methods to discount the speaker-specific traits (e.g., speaker normalization or speaker-independent evaluation), but disassociating speaker-specific traits from the characteristics of a pathological condition remains challenging~\cite{berisha2013selecting}. Intra-speaker variability, which can be due to performance fatigue or other passing factors, should also be modeled. In fact, finding a speaker's true baseline speaking attributes remains one of the most challenging paralinguistic tasks; yet, if that baseline can be established, one can see the great potential of speaker-specific models that can be used for tracking intervention outcome.
%and should be suppressed for most effective evaluation of the conditions. 
%Apart from the application of standard techniques such as speaker normalization and speaker independent cross-validation during model evaluation, standardization techniques accounting for differences in sources of pathological condition and scientific regulation of population demographics (e.g., race, gender) should also be performed.

\section{Domain-Knowledge and Data-Driven Analysis of Pathological Conditions} 
\label{sec:domainknowledgeDatadriven}

Although accounting for all the discussed factors using ML-SP techniques can be fairly complex, researchers have made strides in mining intricate patterns from pathological speech. Given the complex nature of pathological conditions, researchers have explored various ML-SP modeling approaches. We discuss two aspects of previous research: (i) feature design from pathological speech signals, and (ii) machine learning algorithms for capturing various feature patterns in pathological speech. These methods offer a combination of domain knowledge and data driven techniques and have shown promise in analysis of pathological speech.
 
\subsection{Feature Design}
Several works on speech pathology \cite{lass1989speech,berry1942speech,wingate1964standard} describe unique traits of various pathological conditions. 
Previous studies have attempted to capture the wide variety of these traits through various acoustic and phonological features, as well as non-verbal discourse markers.

%Psycholinguistic studies have traditionally linked abnormal prosody to various pathological cases. Motivated by these, voice quality and prosodic features have been extensively used because of their high interpretability and computational efficiency~\cite{van2010computational,tsanas2012novel,bone2014psychologist}, while multi-scale spectro-temporal modulation indices attempt to represent the irregular spectral perturbations of pathological speech~\cite{liss2010discriminating,falk2012characterization,williamson2015automatic}.

The link found in many psycholinguistic studies between abnormal prosody and various pathological cases has motivated the use of voice quality and prosodic features because of their high interpretability and computational efficiency~\cite{van2010computational,tsanas2012novel,bone2014psychologist}. In a more computationally intense framework, multi-scale spectro-temporal modulation indices attempt to represent the irregular spectral perturbations and timing variations of pathological speech~\cite{liss2010discriminating,falk2012characterization,williamson2015automatic}. Motivated by irregularities in the motor function caused by vocal disorders~\cite{falk2012characterization,hahm2015parkinson}, vocal source excitation and articulatory features have been proposed in order to capture the malfunctioning of various parts of the speech production system. Other efforts have focused on developing distance measures between healthy and pathological speech~\cite{gu2005disordered}. These frame-level features can be incorporated into long-term measures through phone or utterance level functionals~\cite{kim2015automatic}, contour parameterization~\cite{kim2015automatic2}, and other non-linear transformations~\cite{kim2015automatic,an2015automatic,middag2011combining}.

ASR can yield confidence indices of normal speech through lattice posteriors and recognition accuracy metrics~\cite{kim2015automatic,zlotnik2015random,maier2009peaks,sharma2009universal,middag2009automated}. ASR output is further able to provide durational features at the syllable and word level that can be indicative of atypicality~\cite{an2015automatic,duez2006consonant}, such as stuttering or dysathrea. Despite the knowledge-driven nature of this approach, challenges of using ASR metrics include the potentially limited vocabulary size, the existence of sparse multilingual data, and the need for speaker-dependent acoustic models.

Non-verbal vocalizations are an essential part of spoken communication for regulating and coordinating discourse. Their atypical occurrence and expression has been related to various neurological and mental disorders~\cite{lake2011listener}. Previous studies have examined the role of fillers, pauses, and laughters in pathological speech and have discussed how the absence or irregular occurrence of these non-verbal vocalizations can indicate pathological symptoms~\cite{heeman2010autism,lake2011listener,gupta2014predicting}.

The inherently diverse information present in the speech signal, such as speaker traits, gender and age effects, environmental conditions, etc., makes it hard to disentangle actual pathology-dependent conditions from other factors. Although previous studies have indicated strong correlates of many of the aforementioned features to pathological constructs, careful methodological and experimental planning has to be conducted in order to make sure that the segmentation of the acoustic features space is performed in terms of the relevant pathological effects~\cite{bone2013classifying}. Towards this direction, ecological data capture procedures, reduced-size interpretable features, appropriate statistical analysis, and legitimate experimental validation are encouraged.

\subsection{Machine Learning}
From the point of view of machine learning methods in pathological speech, a major challenge is posed by the subjectivity of expert annotated labels.
Several researchers have proposed methods to address this problem using novel methods.
For instance, Berisha et. al. \cite{berisha2014modeling} proposed a feature selection method using similarity labels with the annotators being asked to rate the similarity between utterances instead of individual intelligibility ratings. 
Wallen et al. \cite{wallen1996screening} developed a screening test for speech pathology assesment by developing objective quality measures instead of using subjective judgements from humans.
Saenz-Lechon et. al \cite{saenz2006methodological} further discuss issues in development of automatic systems for detection of pathological voice and focus on issues such as speaker variability, subjectivity, data sparsity.
%This issue has been somewhat alleviated by design of knowledge-drive features informative of the underlying condition. 
%However, despite progress in development of features directed towards capturing specific pathological traits, a kitchen sink approach to feature design is often adopted for this task. 
%For example, it is common in speech pathology challenges to begin with an exhaustive set of low-level speech features such as F0, MFCC, LPC coeff. etc., their statistics and functionals. This approach was popularized by the Opensmile toolbox \cite{eyben2010themunich} and has since then been adopted as the baseline approach for several audio and speech based challenges \cite{}. Since the feature dimensionality is typically high, any further processing is usually preceded by a supervised feature selection stage.
%While this method might be promising in relieving researchers of tedious, problem-specific and time-consuming feature design the pitfalls become evident in the context of the data sparsity problem inherent in many of the speech pathology tasks. 
%For many speech pathology tasks, annotation is an expensive process and the amount of data available is often not sufficient to learn reliable models given the large variability in the patterns of interest. This problem is further compounded when the system additionally lacks knowledge-driven reliable features for the task. For example, we consistently find that a few application specific hand-designed features outperform a set of generic audio features\cite{kim2013pathology}. Hence, atleast for the time being, feature design might be essential in the context of low-resource tasks in speech pathology.
%Several researchers have addressed a part of the sparsity problem by application of novel data reduction techniques towards capturing patterns indicative of pathological speech on a large set of standard speech features.
%This however should in no way be taken to imply that the scope of data-driven techniques in pathological speech is limited. 
%Rather, there is an increasing need for machine learning approaches that are cognizant of the domain. 
%For example, to deal with the subjective nature of speech intelligibility ratings, Berisha et. al. \cite{berisha2014modeling} proposed a feature selection method using similarity labels with the annotators being asked to rate the similarity between utterances instead of individual intelligibility ratings.
%posterior smoothing
%In \cite{kim2013pathology} the authors similarly proposed the idea to jointly leverage similarity between samples in the acoustic speaker space on the test set to correct predicted labels in a post processing step. This effectively allows to pool together samples during prediction allowing robustness to large variability within a small dataset.
%Max ent rel
More recently, the authors in \cite{kumar2015maxentrel} proposed a reliability-aware intelligibility classification model that takes into account the subjective nature of annotations. Each annotation is decomposed into two components- a data dependent component representing the objective nature of the annotation and a data-independent component that models the annotator's ownsubective bias. This reliability estimation can be performed at the time of training and can help provide insight into features that are useful in speech pathological conditions.
Another challenge in speech pathology results from the fact that depending on the source of pathological disorder the symptoms for reduced intelligibility might considerably differ. A mixture-of-experts approach was proposed in \cite{gupta2014pathology} to deal with this problem, by training multiple experts for these different conditions in a data-driven fashion.

Apart from these directed approaches towards challenges in modeling pathological speech, several researchers have also resorted to transfer of existing methods to the domain of pathological speech processing.
A few examples \cite{godino2006dimensionality,umapathy2005feature} include using a combination of standard speech features and dimensionality reduction techniques of detecting pathological speech.
Similarly, Chen et al. \cite{chen2007svm} and Oue et al. \cite{oueautomatic} used support vector machines and deep belief networks for identification of pathological voices and disfluency detection in dysarthric speech.
The list of hand designed features and machine leaning techniques for investigating pathological voice is ever increasing and we list a few more of these in the next section, developed for the purpose of specific case studies.

\section{Case Studies of Computational Pathological Speech Analysis}
In this section, we focus on case studies of pathological speech analysis, listing a few studies which have earned considerable interest in the field. We analyze the characteristics of these case studies, discussing methodologies, limitations, and suggestions regarding design of future studies.
In particular, we focus on (i) pathological speech sub-challenge, Interspeech 2012, (ii) Parkinson's condition sub-challenge, Interspeech 2012, and (iii) study of mental health disorders affecting speech. 
These case studies address components of understanding pathological speech, such as assessing intelligibility of speech and analyzing speech quality, and offer piecemeal solutions towards the larger problem of complete quantitative understading of pathological speech production and perception.

\subsection{Pathological Speech Sub-Challenge, Interspeech 2012}
%Recently, an automatic assessment system for speech intelligiblity and quality has been obtaining lots of attention for assisting speech therapy and the and the pathological speech sub-challenge was a step towards this.
There has been considerable interest to develop automatic assessment system for speech intelligibility and quality. It was hoped to offer more accurate, objective and scalable engineering solutions in order to assist speech therapies in clinical practice. Pathological speech sub-challenge in Interspeech 2012 was designed to bring more attentions from speech signal processing and machine learning communities into this domain and promote technical advance in this area.
%Since manual evaluation by human experts is costly, time-consuming, and subjective, 
In particular, this challenge called for developing an automatic system to analyze and judge the speech intelligibility of patients suffering from pathological speech due to neck and head tumors.
The challenge dataset contained speech audio of the patients, recorded before and after a chemo-radiation treatment in order to monitor their speech intelligibility during the period of the treatment and speech therapy.
%Furhtermore, the patients were evaluated based on a recitation of a dutch script whereas not all of them were native duthc speakers. 
The speech audio was recorded while the patients were reading Dutch sentences, whereas some of them were not the native speakers of Dutch.
The intelligibility of individual speech utterances was judged on a scale of 1-7 by 13 experts.

This data set design has several interesting implications.
First of all, the longitudinal speech data allows for the evaluation of the progress of speech therapy to improve the speech intelligibility.
%studies like this allow for evaluating the effectiveness of treatment being administered.
This can be crucial in determining the course of treatment for a patient.
Secondly, an attempt is made to reduce the subjectivity and variability of expert judgements by using 13 of them.
For the purpose of the challenge, the final intelligibility score for each utterance was determined as the weighted sum of individuals' ratings.
A combination of expert judgements has been shown to reduce annotator noise \cite{} and we encourage the application of recently developed multiple annotator schemes used for determining the final intelligibility label. 
Another intersting aspect of the data is that the data contains speech audio of both native and non-native speakers. Although it fits a realistic scenario in clinical practice, this presents ML-SP methods a challenge of accounting for patient variability as we discussed in section \ref{sec:PatVar}.
The nativeness of a speaker affects the intelligibility of the speech sound as well \cite{van2001intelligibility}, hence it is important to segregate the impact of the disease and the treatment v.s. the nativeness of the speaker on the speech intelligibility.

Within the scope of this challenge, one of the prominent machine learning approaches was use of a large feature set coupled with dimensionaltiy reduction techniques. 
For instace, Kim et al. \cite{kim2012intelligibility} developed multiple expert subsystems on feature subsets, which were finally fused using Bayesian fusion models (Naive Bayes or Noise-Majority system).
Lu et al. \cite{lu2012predicting} used sparse Gaussian process, Huang et al. ~\cite{huang2012detecting} used asymmetrical sparse partial least squares regression and Zhou et al. \cite{zhou2012automatic} applied a combination of LDA and PCA techniques.
On the other hand, some paper designed acoustic features inspired by neurophysiology, biophysics and psychoacoustics for intelligibility assessment \cite{zhou2012automatic}. 
Finally, Stark et al. \cite{stark2012interspeech} investigated the impact of speaker and sentence on intelligibility assesments probing questions related to generality versus specificity.

Overall, this challenge presented some unique data characteristics and reseachers presented novel methods answering some questions related to application of ML-SP tools.
In the next section, we describe another Interspeech challenge for automatic rating of Parkinson's disease severity from speech. 

%This challenge also lead to the development of several ML-SP techniques addressing intellibility inference from speech cues.  
%The winner of the challege~\cite{kim2012intelligibility} developed multiple expert subsystems which were fused for the final label by using Bayesian fusion models (Naive Bayes or Noise-Majority system).
%Individual subsystem focuses on particular aspects of speech, e.g., acoustic similarity to normal speech, prosody, intonation, voice quality and pronunciation quality.
%Acoustic features include pitch stylization parameters (quadratic polynomials) for pitch trajectory, speaking rate, harmony-noise ratio, jitter, shimmer, Mel-Frequency Cepstral Coefficients (MFCCs), formants, and phoneme probability feature driven from Automatic Speech Recognition (ASR) lattice.
%They employed joint classification scheme: an ad-hoc way of utilizing the high similarity of intelligibility score for the speech audio closely located in the acoustic space.

%Ways to handle high feature dimensionality were examined in this challenge.
%In order to capture a variety of atypicality in pathological speech, a large number of acoustic features is initially extracted.
%Hence, some feature reduction techniques were applied for achieving high accuracy on the test set.
%Sparse Gaussian process was introduced in~\cite{lu2012predicting}, where the original features were transformed to a lower dimensional feature space using kernel PCA.
%Asymmetric sparse partial least squares regression were also tested in~\cite{huang2012detecting}.
%Modified LDA was tested to further reduce the feature dimension from initially reduced dimension by PCA in~\cite{zhou2012automatic}.

\subsection{Parkinson's Condition Sub-Challenge, Interspeech 2015}
%Parkinson's disease is one of the most common neurological disorders.
%In clinical practice, it is important to track the severity of its symptom.
%Using speech signal for monitoring the pregression of Parkinson's disease is an attractive approach, because it is non-invasive, fast, easy-to-obtain and cost-efficient as well as useful for speech treatment.
%The task of the Parkinson's condition challenge in Interspeech 2015 was to develop an automatic system to predict the severity of Parkinson disease using a set of speech signals of the patients.
%
%Various features on top of the standard baseline features extracted using openSMILE~\cite{eyben2010themunich} were tested for automatic severity rating.
%Rhythmic features adpoted from music information retrieval include beatspectrum~\cite{foote2002audio} and spectral irregularity~\cite{jensen1999timbre}.
%The structure of correlations among frame-level speech features were also captured using channel-delay correlation and covariance matrices on the speech waveform, delta-MFCCs and formants, and the articulatory feature streams predicted using the Directions into Velocities of Articulators (DIVA) model~\cite{guenther2006neural,williamson2015segment}.
%Using both acoustic and (predicted) articulatory information improved prediction accuracy~\cite{hahm2015parkinson}.
%
%Since the goal was to achieve the best Spearman correlation between predicted and true labels, that is the Unified Parkinson's Disease Rating Scale (UPDRS)~\cite{stebbins1998factor}, participatns tested various regressors, e.g. support vector regressor, random forest, deep neural networks and Gaussian staircase regression model~\cite{williamson2013vocal}. The winning system~\cite{grosz2015assessing} in this challenge used a deep neural network regressor on the average of multiple predictors' scores - the predictors were diversified with different hyperparameter values. 
%
%In the challenge dataset, the UPDRS score was assigned to each speaker, not each utterance.
%Hence, judging the final severity score of individual utterances based on all utterances of each speaker (or each UPDRS-score cluster) improved prediction accuracy significantly.
%Specifically, incorporating feature selection~\cite{grosz2015assessing} or the information of (predicted) prompt type~\cite{kim2015automatic} into clustering process improved severity rating accuracy as well as clustering accuracy significantly.
%

Parkinson's disease is one of the most common neurological disorders and effect of Parkinson's disease on speech has been discussed in several works \cite{lieberman1992speech,kempler2002effect}.
The Parkinson's condition sub-challenge at Interspeech 2015 focused on the development of automated rating system for Parkinson's severity using speech cues.
This challenge is different from the previous challenge in the sense that the previous challenge focuses on the effect of pathological speech (intelligibility) whereas this challenge focuses on the cause (Parkinson's disease). 
involved prediction of speech intelligibility caused by tumors.
Using speech signal for monitoring the progression of Parkinson's disease is an attractive approach, because it is non-invasive, fast, easy-to-obtain and cost-efficient as well as useful for speech therapy.
%The task of the Parkinson's condition challenge in Interspeech 2015 was to develop an automatic system to predict the severity of Parkinson disease using a set of speech signals of the patients.

The dataset of this challenge has several unique characteristics. 
First, training and test set partitions were recorded in dissimilar environmental noise conditions.
This scenario is very realistic and calls for development of noise robust systems for a broader use. 
Second, each patient produced 42 speech utterances of five speaking tasks: (i) reading single words, (ii) rapidly repeating syllables, (iii) reading sentences, (iv) reading a text, and (v) speaking spontaneously.
This setup allowed the analysis of the impact of utterance type on different kinds of acoustic atypicality.
Finally, the evaluation of Parkinson's severity was made using the standard Unified Parkinson's Disease Rating Scale (UPDRS)~\cite{stebbins1998factor}.
Availability of such carefully designed standards is crucial in training machine learning systems as they not only provide a ground truth for evaluation but also reduce ambiguity in problem definition while applying ML-SP techniques.

In this challenge, a lot of researchers focused on designing features to capture the spectral and prosodic characteristics of speech, while reducing the impact of differences in recording conditions.
%Various features on top of the standard baseline features extracted using openSMILE~\cite{eyben2010themunich} were tested for automatic severity rating.
Foote el al. \cite{foote2002audio} and Jensen el al. \cite{jensen1999timbre} developed rhythmic features called beatspectrum and spectral irregularity, inspired from music information retrieval.
Guenther el al. \cite{guenther2006neural} and Williamson et al. \cite{williamson2015segment} focused on identifying Parkinson's severity based on channel-delay correlation and covariance matrices on the speech waveform, delta-MFCCs and formants, and the articulatory feature streams predicted using the Directions into Velocities of Articulators (DIVA) model.
Hahm et al. \cite{hahm2015parkinson} used an assembly of both acoustic and articulatory features to predict the UPDRS score.
Kim et al. \cite{kim2015automatic} proposed an interesting approach to predict the UPDRS scores based on the five utterance types and performing a fusion to compute the final severity score for the speaker.

In summary, this challenge along with the Interspeech challenge 2012 provided opportunities to investigate the cause and effect of pathological speech.
Also, the challenges presented various challenges to ML-SP researchers from accounting for speaker specificity to diversity in recoding conditions.
In the next section, we present a summary of research on other mental health disorders that cause pathological speech.

\subsection{Pathological Speech in Developmental and Mental Health Disorders}
Certain types of pathological speech can result from other disorders. 
For instance, autism spectrum disorder (ASD) is a prevalent neuro-cognitive developmental disorder (1 in 68 in the United States~\cite{}) that affects social-communicative aspects of speech and language throughout the lifetime~\cite{}. 
Speech pathologists play a critical role in both the assessment and treatment of ASD~\cite{pathologyWebsite}. 
In terms of acoustical analysis, speech scientists are focusing on speech prosody--the rhythm, stress, and intonation of speech--as a prime means for translational impact. 
This is because, although speech prosody is commonly referred to as 'atypical' in autism, it is not currently utilized in the ``gold-standard'' diagnostic instrument, the Autism Diagnostic Observation Schedule (ADOS)~\cite{ADOS2002}. 
Interestingly, speech scientists may be able to develop computational models of `typical' prosody in order to infer 'atypical' prosody, particularly those that are knowledge-driven; this effort is in contrast to much of the present pathological speech computational methods which attempt to predict a gold-standard ground-truth. 
For instance, Bone et al. (2014) investigated prosodic cues of children with autism (and the interacting psychologist), finding interpretable acoustic measures that corroborate previous qualitative perceptions through correlational analysis and linear-regression prediction with ASD-severity~\cite{}. 
However, noting that not all individuals with autism will have a prosodic deficit, Bone et al. (2015) also incorporated global human judgements of prosodic `awkwardness'~\cite{}. 
Thus, we see in this case example that providing a computational measure which does not currently have an established ground truth can be quite challenging, but also could be of high-value to the target domain.

these fields can have a symbiotic relationship, with each learning from the other

Another example is.... addiction etc. Jimmy, Bo

\section{Conclusion and Future Paths}
Lots of current work, limited in generalization due to various sources of variability.

Continued collaboration of different disciplines and novel experimental methodologies.
\vfill\pagebreak

% BiBTeX files (here: strings, refs, manuals). The IEEEbib.bst bibliography
% style file from IEEE produces unsorted bibliography list.
% -------------------------------------------------------------------------
\bibliographystyle{IEEEbib}
\bibliography{strings,refs}

\end{document}
